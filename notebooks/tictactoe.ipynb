{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "657fe9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import khet\n",
    "import random\n",
    "import pylab as plt\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e797cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a9722",
   "metadata": {},
   "source": [
    "## Alpha-beta pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "178863ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def evaluate(board, player):\n",
    "    \"\"\"\n",
    "    Evaluate the current state of the tic-tac-toe board for the given player.\n",
    "\n",
    "    Parameters:\n",
    "    - board: 3x3 list representing the tic-tac-toe board\n",
    "    - player: The player for whom the evaluation is performed ('X' or 'O')\n",
    "\n",
    "    Returns:\n",
    "    - A numerical score indicating the desirability of the board for the player\n",
    "    \"\"\"\n",
    "\n",
    "    # Check for a win\n",
    "    if is_winner(tupleize(board), player):\n",
    "        return 100  # Player wins, maximum score\n",
    "\n",
    "    # Check for a loss\n",
    "    opponent = 'O' if player == 'X' else 'X'\n",
    "    if is_winner(tupleize(board), opponent):\n",
    "        return -100  # Opponent wins, minimum score\n",
    "\n",
    "    # Check for a draw\n",
    "    if is_board_full(board):\n",
    "        return 0  # Draw\n",
    "    \n",
    "    # return 0\n",
    "\n",
    "    # No decisive outcome yet, evaluate based on potential for future wins\n",
    "    player_score = evaluate_player_moves(board, player)\n",
    "    opponent_score = evaluate_player_moves(board, opponent)\n",
    "\n",
    "    return player_score - opponent_score\n",
    "\n",
    "def is_game_over(board):\n",
    "    return is_winner(tupleize(board), 'X') or is_winner(tupleize(board), 'O') or is_board_full(board)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def is_winner(board, player):\n",
    "    # Check rows, columns, and diagonals for a win\n",
    "    nrows = len(board)\n",
    "    \n",
    "    return any(\n",
    "        all(cell == player for cell in row) or  # Check rows\n",
    "        all(board[i][j] == player for i in range(nrows)) or  # Check columns\n",
    "        all(board[i][i] == player for i in range(nrows)) or  # Check main diagonal\n",
    "        all(board[i][nrows - 1 - i] == player for i in range(nrows))  # Check secondary diagonal\n",
    "        for j, row in enumerate(board)\n",
    "    )\n",
    "\n",
    "def _is_winner(board, player):\n",
    "    # Check rows, columns, and diagonals for a win\n",
    "    nrows = len(board)\n",
    "    \n",
    "    return any(\n",
    "        all(cell == player for cell in row) or  # Check rows\n",
    "        all(board[i][j] == player for i in range(nrows)) or  # Check columns\n",
    "        all(board[i][i] == player for i in range(nrows)) or  # Check main diagonal\n",
    "        all(board[i][nrows - 1 - i] == player for i in range(nrows))  # Check secondary diagonal\n",
    "        for j, row in enumerate(board)\n",
    "    )\n",
    "\n",
    "def tupleize(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return tuple([tuple(r) for r in x])\n",
    "\n",
    "\n",
    "def is_board_full(board):\n",
    "    # Check if the board is full (a draw)\n",
    "    return all(all(cell for cell in row) for row in board)\n",
    "\n",
    "\n",
    "def evaluate_player_moves(board, player):\n",
    "    # Evaluate potential future wins for the player\n",
    "    score = 0\n",
    "    opponent = 'O' if player == 'X' else 'X'\n",
    "\n",
    "    nrows = len(board)\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        for j in range(nrows):\n",
    "            if board[i][j] is None:\n",
    "                # Simulate making a move for the player\n",
    "                board[i][j] = player\n",
    "\n",
    "                # Check if the move leads to a win\n",
    "                if is_winner(tupleize(board), player):\n",
    "                    score += 1\n",
    "                    \n",
    "                elif is_winner(tupleize(board), opponent):\n",
    "                    score -= 3\n",
    "\n",
    "                # Undo the move for the next iteration\n",
    "                board[i][j] = None\n",
    "\n",
    "    return score\n",
    "\n",
    "def make_move(board, move, color):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    bb = deepcopy(board)\n",
    "    if bb[move[0]][move[1]] is None:\n",
    "        bb[move[0]][move[1]] = color\n",
    "\n",
    "    return bb\n",
    "\n",
    "def get_all_valid_moves(board):\n",
    "    moves = []\n",
    "    nrows = len(board)\n",
    "    for i in range(nrows):\n",
    "        for j in range(nrows):\n",
    "            if board[i][j] is None:\n",
    "                moves.append((i, j))\n",
    "                \n",
    "    return moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e085525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "transposition_table = {}\n",
    "opponent_map = {'X': 'O', \"O\": \"X\"}\n",
    "\n",
    "def alpha_beta_search(\n",
    "    board, depth, alpha=-math.inf, beta=math.inf, maximizing_player=True, player='X'\n",
    "):\n",
    "    \"\"\"\n",
    "    Maximizing player is X here\n",
    "    \"\"\"    \n",
    "    if player == 'X':\n",
    "        max_player = 'X'\n",
    "        min_player = 'O'\n",
    "    else:\n",
    "        max_player = 'O'\n",
    "        min_player = 'X'\n",
    "        \n",
    "    if depth == 0 or is_game_over(board):\n",
    "        return evaluate(board, max_player), (-1, -1)\n",
    "\n",
    "    # Get all of the potential legal moves\n",
    "    legal_moves = get_all_valid_moves(board)\n",
    "\n",
    "    if maximizing_player:\n",
    "        best_move = None\n",
    "        max_eval = -math.inf\n",
    "        for move in legal_moves:\n",
    "            new_board = make_move(board, move, max_player)\n",
    "            eval_score, _move = alpha_beta_search(\n",
    "                new_board, depth - 1, alpha, beta, False, player=max_player\n",
    "            )\n",
    "            if eval_score > max_eval:\n",
    "                max_eval = eval_score\n",
    "                best_move = move\n",
    "                \n",
    "            alpha = max(alpha, eval_score)\n",
    "\n",
    "            if beta <= alpha:\n",
    "                break  # Beta cutoff\n",
    "\n",
    "        return alpha, best_move\n",
    "\n",
    "    else:\n",
    "        best_move = None\n",
    "        min_eval = math.inf\n",
    "        for move in legal_moves:\n",
    "            new_board = make_move(board, move, min_player)\n",
    "            eval_score, _move = alpha_beta_search(\n",
    "                new_board, depth - 1, alpha, beta, True, player=max_player\n",
    "            )\n",
    "            if eval_score < min_eval:\n",
    "                min_eval = eval_score\n",
    "                best_move = move\n",
    "                \n",
    "            beta = min(beta, min_eval)\n",
    "            \n",
    "            if beta <= alpha:\n",
    "                break  # Alpha cutoff\n",
    "\n",
    "        return beta, best_move\n",
    "    \n",
    "class Bot:\n",
    "    def __init__(self, marker='X', mode='random'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        assert marker in ['X', \"O\"]\n",
    "        self.marker = marker\n",
    "        assert mode in ['random', 'minimax']\n",
    "        self.mode = mode\n",
    "    \n",
    "    def make_move(self, board, depth=5):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.mode == 'minimax':\n",
    "            _, move = alpha_beta_search(board, depth, maximizing_player=True, player=self.marker)\n",
    "        else:\n",
    "            all_moves = get_all_valid_moves(board)\n",
    "            move = all_moves[random.randint(0, len(all_moves) - 1)]\n",
    "            \n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "883339b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(board):\n",
    "    for row in board:\n",
    "        print (\"\".join(['.' if i is None else i for i in row]))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "05f99edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(\n",
    "    player1_bot=True,\n",
    "    bot1_type=\"minimax\",\n",
    "    depth1=5,\n",
    "    player2_bot=True,\n",
    "    bot2_type=\"random\",\n",
    "    depth2=5,\n",
    "    verbose=True,\n",
    "    first_move_random=True,\n",
    "    marker1='X',\n",
    "    marker2='O'\n",
    "):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    player1 = Bot(mode=bot1_type, marker=marker1)\n",
    "    player2 = Bot(mode=bot2_type, marker=marker2)\n",
    "    nrows = 3\n",
    "\n",
    "    board = [[None for j in range(nrows)] for i in range(nrows)]\n",
    "    if verbose:\n",
    "        print_board(board)\n",
    "\n",
    "    boards = []\n",
    "\n",
    "    ci = 0\n",
    "\n",
    "    while not is_game_over(board):\n",
    "        if ci == 0 and first_move_random:\n",
    "            player1.mode = \"random\"\n",
    "            move = player1.make_move(board, depth=depth1)\n",
    "            player1.mode = bot1_type\n",
    "        else:\n",
    "            move = player1.make_move(board, depth=depth1)\n",
    "\n",
    "        board = make_move(board, move, marker1)\n",
    "        boards.append(board)\n",
    "        if is_game_over(board):\n",
    "            break\n",
    "\n",
    "        move = player2.make_move(board, depth=depth2)\n",
    "        board = make_move(board, move, marker2)\n",
    "        boards.append(board)\n",
    "\n",
    "        if verbose:\n",
    "            print_board(board)\n",
    "\n",
    "        ci += 1\n",
    "\n",
    "    if verbose:\n",
    "        print_board(board)\n",
    "    return boards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c419577",
   "metadata": {},
   "source": [
    "## Minimax Algorithm w/ Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b802d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngames = 1000\n",
    "games = []\n",
    "for n in range(ngames):\n",
    "    games.append(\n",
    "        play_game(\n",
    "            bot1_type=\"minimax\",\n",
    "            bot2_type=\"random\",\n",
    "            depth1=3,\n",
    "            depth2=1,\n",
    "            verbose=False,\n",
    "            first_move_random=False,\n",
    "            marker1='O',\n",
    "            marker2='X'\n",
    "        )[-1]\n",
    "    )\n",
    "    \n",
    "wins = 0\n",
    "losses = 0\n",
    "ties = 0\n",
    "for game in games:\n",
    "    if is_winner(tupleize(game), 'O'):\n",
    "        wins += 1\n",
    "    elif is_winner(tupleize(game), 'X'):\n",
    "        losses += 1\n",
    "    else:\n",
    "        ties += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "13f51816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimax algorithm won 991 games, lost 0 games, and tied 9 games as first player\n"
     ]
    }
   ],
   "source": [
    "print (\"Minimax algorithm won\", wins, \"games, lost\", losses, \"games, and tied\", ties, \"games as first player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "02b8cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngames = 1000\n",
    "games = []\n",
    "for n in range(ngames):\n",
    "    games.append(\n",
    "        play_game(\n",
    "            bot1_type=\"random\",\n",
    "            bot2_type=\"minimax\",\n",
    "            depth1=1,\n",
    "            depth2=4,\n",
    "            verbose=False,\n",
    "            first_move_random=False,\n",
    "            marker1='O',\n",
    "            marker2='X'\n",
    "        )[-1]\n",
    "    )\n",
    "    \n",
    "wins = 0\n",
    "losses = 0\n",
    "ties = 0\n",
    "for game in games:\n",
    "    if is_winner(tupleize(game), 'X'):\n",
    "        wins += 1\n",
    "    elif is_winner(tupleize(game), 'O'):\n",
    "        losses += 1\n",
    "    else:\n",
    "        ties += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "17cd4e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimax algorithm won 816 games, lost 0 games, and tied 184 games as second player\n"
     ]
    }
   ],
   "source": [
    "print (\"Minimax algorithm won\", wins, \"games, lost\", losses, \"games, and tied\", ties, \"games as second player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef3c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return\n",
    "    \n",
    "    def search(state, game, nnet):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if is_game_over(game):\n",
    "            return \n",
    "        \n",
    "        if s not in visited:\n",
    "            visited.add(s)\n",
    "            P[s], v = nnet.predict(s)\n",
    "            return -v\n",
    "        \n",
    "        max_u, best_a = -float('inf'), -1\n",
    "        for a in get_all_valid_moves(game):\n",
    "            u = Q[s][a] + c_puct * P[s][a] * np.sqrt(sum(N[s])) / (1 + N[s][a])\n",
    "            \n",
    "            if u > max_u:\n",
    "                max_u = u\n",
    "                best_a = a\n",
    "                \n",
    "        a = best_a\n",
    "        Q[s][a] = (N[s][a]*Q[s][a] + v) / (N[s][a] + 1)\n",
    "        N[s][a] += 1\n",
    "        return -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f91c0",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "This approach uses reinforcement learning to train a neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "12f2ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "873cc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(state, outcome, network, pi):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    logits = network(state)\n",
    "    prob = nn.Softmax(dim=1)(logits[:, :-1])\n",
    "    vs = logits[:, -1]\n",
    "    return torch.square(outcome - vs).sum() - torch.sum(pi * torch.log(prob))\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(9, 45),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(45, 45),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(45, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9959d",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathcal{L} = \\sum_t \\left(v_\\theta\\left(s_t\\right) - z_t\\right)^2 - \\vec{\\pi}_t \\cdot \\log\\left(\\vec{p}_\\theta\\left(s_t\\right)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "561691c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "did = {}\n",
    "did[None] = 0\n",
    "did[\"X\"] = 1\n",
    "did['O'] = -1\n",
    "\n",
    "# Simulate games in this cell\n",
    "ngames = 1000\n",
    "games = []\n",
    "\n",
    "for n in range(ngames):\n",
    "    _here_games = play_game(\n",
    "            bot1_type=\"minimax\",\n",
    "            bot2_type=\"random\",\n",
    "            depth1=3,\n",
    "            depth2=1,\n",
    "            verbose=False,\n",
    "            first_move_random=True,\n",
    "            marker1='X',\n",
    "            marker2='O'\n",
    "        )\n",
    "    all_games = list(map(lambda game: sum(game, []), _here_games))\n",
    "    all_games = [[did[square] for square in g] for g in all_games]\n",
    "    games.append(all_games)\n",
    "    #games += all_games\n",
    "    \n",
    "results = []\n",
    "for game in games:\n",
    "    g = game[-1]\n",
    "    if _is_winner([g[:3], g[3:6], g[6:9]], 1):\n",
    "        results += [1]\n",
    "    elif _is_winner([g[:3], g[3:6], g[6:9]], -1):\n",
    "        results += [-1]\n",
    "    else:\n",
    "        results += [0]\n",
    "        \n",
    "states = np.array(sum(games, []))\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_function(y_pred, ybatch)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d791b37",
   "metadata": {},
   "source": [
    "## Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ff990852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self, nsquares=3):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.board = [[None for _ in range(nsquares)] for _ in range(nsquares)]\n",
    "                \n",
    "    def get_all_valid_moves(self):\n",
    "        moves = []\n",
    "        nrows = len(self.board)\n",
    "        for i in range(nrows):\n",
    "            for j in range(nrows):\n",
    "                if self.board[i][j] is None:\n",
    "                    moves.append((i, j))\n",
    "\n",
    "        return moves\n",
    "    \n",
    "    def make_move(self, move, player):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.board[move[0]][move[1]] = player\n",
    "    \n",
    "    @property\n",
    "    def state(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return \"\".join([item if item else '.' for row in self.board for item in row])\n",
    "    \n",
    "\n",
    "def predict(game):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    moves = game.get_all_valid_moves()\n",
    "    prob = np.random.uniform(0, 1, size=len(moves))\n",
    "    prob /= prob.sum()\n",
    "    return {m: p for m, p in zip(moves, prob)}, np.random.uniform(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "2e1b0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_repr(game):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return \"\".join([item if item else \".\" for row in game for item in row])\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.Q = {}  # stores Q values for state and action\n",
    "        self.Nsa = {}  # stores times state and action were visited\n",
    "        self.P = {}  # stores initial policy\n",
    "        self.N = {}  # stores times state was visited\n",
    "        self.Es = {}  # stores whether state is terminal\n",
    "        self.Vs = {}  # stores valid moves for state s\n",
    "        self.visited = set()\n",
    "\n",
    "    def get_action_prob(self, game, nsims=100):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for _ in range(nsims):\n",
    "            self.search(game)\n",
    "\n",
    "        s = get_state_repr(game)\n",
    "        counts = [\n",
    "            self.Nsa[(s, a)] if (s, a) in self.Nsa else 0\n",
    "            for a in get_all_valid_moves(game)\n",
    "        ]\n",
    "        \n",
    "        counts_sum = np.sum(counts)\n",
    "        probs = np.array(counts) / counts_sum\n",
    "        return probs\n",
    "\n",
    "    def search(self, game, c_puct=1):\n",
    "        \"\"\"\n",
    "        Fix search function\n",
    "        \"\"\"\n",
    "        board = game.board\n",
    "        \n",
    "        if is_game_over(board):\n",
    "            return\n",
    "\n",
    "        s = get_state_repr(board)\n",
    "        \n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = game\n",
    "\n",
    "        # leaf node\n",
    "        if s not in self.P:\n",
    "            self.P[s], v = self.predict(board)\n",
    "            valids = get_all_valid_moves(board)\n",
    "            self.P[s] *= valids\n",
    "            self.P[s] /= self.P[s].sum()\n",
    "            self.Vs[s] = valids\n",
    "            self.Ns[s] = 0\n",
    "            return -v\n",
    "        \n",
    "        valids = self.Vs[s]\n",
    "        current_best, best_action = -float('inf'), -1\n",
    "\n",
    "        for a in get_all_valid_moves(game):\n",
    "            if valids[a]:\n",
    "                if (s, a) in self.Qsa:\n",
    "                    u = self.Qsa[(s, a)] + c_puct * self.P[s][a] * np.sqrt(self.Ns[s]) / (1 + self.Nsa[(s, a)])\n",
    "            else:\n",
    "                u = c_puct * self.P[s][a] * np.sqrt(self.Ns[s] + 1e-4)\n",
    "\n",
    "            if u > current_best:\n",
    "                current_best = u\n",
    "                best_action = a\n",
    "\n",
    "        a = best_action\n",
    "        make_move(game, player)\n",
    "        \n",
    "        if (s, a) in self.Qsa:\n",
    "            self.Qsa[(s, a)] = (self.Nsa[(s, a)] * self.Qsa[(s, a)] + v) / (self.Nsa[(s, a)] + 1)\n",
    "            self.Nsa[(s, a)] += 1\n",
    "        else:\n",
    "            self.Qsa[(s, a)] = v\n",
    "            self.Nsa[(s, a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "835ab19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.........'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = TicTacToe()\n",
    "get_state_repr(game.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d832cd2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MCTS' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [415]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m num_mcts_sims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_mcts_sims):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mmcts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [413]\u001b[0m, in \u001b[0;36mMCTS.search\u001b[0;34m(self, game, c_puct)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# leaf node\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP[s], v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(board)\n\u001b[1;32m     52\u001b[0m     valids \u001b[38;5;241m=\u001b[39m get_all_valid_moves(board)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP[s] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m valids\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MCTS' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "mcts = MCTS()\n",
    "num_mcts_sims = 20\n",
    "\n",
    "for _ in range(num_mcts_sims):\n",
    "    mcts.search(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d93b94bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mcts.P['.........'].values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
